{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('tweets.csv')\n",
    "\n",
    "tweets = df['text']\n",
    "\n",
    "replypattern = '@[\\w]+'\n",
    "urlpattern = 'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+'\n",
    "\n",
    "processedtweets = []\n",
    "counting = 1\n",
    "for tweet in tweets:\n",
    "    counting += 1\n",
    "    if counting == 10:\n",
    "        break\n",
    "    i = re.sub(replypattern, '', tweet)\n",
    "    i = re.sub(urlpattern, '', i)\n",
    "    if isinstance(i, str) and not i.split():\n",
    "        pass\n",
    "    else:\n",
    "        processedtweets.append(i)\n",
    "\n",
    "processedtweetsDataFrame = pd.Series(processedtweets)\n",
    "newDF = pd.DataFrame({'text': processedtweetsDataFrame})\n",
    "\n",
    "newDF.to_csv('processedtweets.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram(text, n):\n",
    "    results = []\n",
    "    if len(text) >= n:\n",
    "        for i in range(len(text)-n+1):\n",
    "            results.append(text[i:i+n])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['さす',\n",
       " 'すが',\n",
       " 'がに',\n",
       " 'に1',\n",
       " '15',\n",
       " '5泊',\n",
       " '泊は',\n",
       " 'は無',\n",
       " '無理',\n",
       " '理や',\n",
       " 'やん',\n",
       " 'んl',\n",
       " 'lo',\n",
       " 'ol',\n",
       " 'l\\n',\n",
       " '\"1',\n",
       " '12',\n",
       " '2/',\n",
       " '/2',\n",
       " '23',\n",
       " '3~',\n",
       " '~1',\n",
       " '1/',\n",
       " '/7',\n",
       " '7ま',\n",
       " 'まで',\n",
       " 'での',\n",
       " 'のプ',\n",
       " 'プラ',\n",
       " 'ラン',\n",
       " 'ンに',\n",
       " 'にな',\n",
       " 'なっ',\n",
       " 'って',\n",
       " 'て草',\n",
       " '草生',\n",
       " '生え',\n",
       " 'える',\n",
       " 'る\\n',\n",
       " '無理',\n",
       " '理や',\n",
       " 'や困',\n",
       " '困難',\n",
       " '難\"',\n",
       " '\"\\n',\n",
       " 'むし',\n",
       " 'しろ',\n",
       " 'ろ長',\n",
       " '長め',\n",
       " 'めに',\n",
       " 'にと',\n",
       " 'とっ',\n",
       " 'って',\n",
       " 'てエ',\n",
       " 'エア',\n",
       " 'アー',\n",
       " 'ービ',\n",
       " 'ビエ',\n",
       " 'エヌ',\n",
       " 'ヌビ',\n",
       " 'ビー',\n",
       " 'ーの',\n",
       " 'の宿',\n",
       " '宿泊',\n",
       " '泊費',\n",
       " '費と',\n",
       " 'と相',\n",
       " '相殺',\n",
       " '殺…',\n",
       " '…？',\n",
       " '？\\n',\n",
       " '年末',\n",
       " '末の',\n",
       " 'のコ',\n",
       " 'コミ',\n",
       " 'ミケ',\n",
       " 'ケタ',\n",
       " 'タイ',\n",
       " 'イミ',\n",
       " 'ミン',\n",
       " 'ング',\n",
       " 'グは',\n",
       " 'は流',\n",
       " '流石',\n",
       " '石に',\n",
       " 'に無',\n",
       " '無理',\n",
       " '理だ',\n",
       " 'だっ',\n",
       " 'った',\n",
       " 'た\\n',\n",
       " ' 了',\n",
       " '了解',\n",
       " '解し',\n",
       " 'しま',\n",
       " 'まし',\n",
       " 'した',\n",
       " 'た\\n',\n",
       " ' グ',\n",
       " 'グル',\n",
       " 'ルー',\n",
       " 'ープ',\n",
       " 'プ(',\n",
       " '(ソ',\n",
       " 'ソロ',\n",
       " 'ロ)',\n",
       " ')\\n',\n",
       " 'ぼー',\n",
       " 'ーち',\n",
       " 'ち\\n',\n",
       " 'yo',\n",
       " 'og',\n",
       " 'gi',\n",
       " 'i3',\n",
       " '30',\n",
       " '0分',\n",
       " '分も',\n",
       " 'も遅',\n",
       " '遅刻',\n",
       " '刻す',\n",
       " 'すん',\n",
       " 'んの',\n",
       " 'のか',\n",
       " 'か〜',\n",
       " '〜〜',\n",
       " '〜〜',\n",
       " '〜\\n']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('processedtweets.csv')\n",
    "\n",
    "line = f.readline()\n",
    "bygram = []\n",
    "while line:\n",
    "    line = f.readline()\n",
    "    text = line\n",
    "    for e in ngram(text, 2):\n",
    "        bygram.append(e)\n",
    "f.close()\n",
    "bygram"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
